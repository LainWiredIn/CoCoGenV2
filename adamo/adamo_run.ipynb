{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "print(\"Model train karke dekh rahe ho? Good luck!\")\n",
        "time.sleep(3)\n",
        "print(\"Do you really think model train ho jayega humare jaiso ka?\")\n",
        "time.sleep(3)"
      ],
      "metadata": {
        "id": "WGaznt--0TNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBfw8K_9cnTx",
        "outputId": "65373f9b-b866-488a-cfc8-2dee7cb8627a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.61.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder list\n",
            "Retrieving folder 1yo6bHZCz6Jcx-0FkTGva7BA37TkjvBY7 Java\n",
            "Retrieving folder 1CRb2JDprf1xUo0YcDwNzgqgsKZHKWzir test\n",
            "Processing file 1Znbl3fJPaq5ki-oie9FLIyaJdkHaaRcU split_test_ast.json\n",
            "Processing file 1OnZ6Wv4hGmbyqZoy9rfuX5rec3cIDJtN test.source\n",
            "Processing file 1sIZAfZj2ob37hNb3cjP-rRrffAXwH0G5 test.token.ast\n",
            "Processing file 1AKek2SWz4AXJL7Kh17-Qss4w3fl2SnFT test.token.code\n",
            "Processing file 1oFrqLk65HH3O05aFnZTDse8qhTUDgAPL test.token.nl\n",
            "Retrieving folder 1KpDZc4P84x-Py4CUYwoxcWKzV10xzM9A train\n",
            "Processing file 1Cns8yxw6sNyM3Um8YddS1nPqHui9Maor split_train_ast.json\n",
            "Processing file 1V1hUSMrp7UlKmTtUf1DWTAxRTkpFntqZ train.source\n",
            "Processing file 1mwAQerruX8KNsAu4ZbGSnV3tjNHSharZ train.token.ast\n",
            "Processing file 180Yf6EboDq3siXtdKBEtyvEBj2NRHwxW train.token.code\n",
            "Processing file 1hV-s1Js0K8QzbKm0oVdd13c5de4Bjx4K train.token.nl\n",
            "Retrieving folder 15nW6gE6gPWPUlVYWGZqX1EMJ39gROp_m valid\n",
            "Processing file 1wEl3ZfLM5S0Vyc1TZP_4Keu_FgY-4wWH split_valid_ast.json\n",
            "Processing file 1Bvz7wXgcZ1aXZ2haL9AaqlvkvhbGoxYP valid.source\n",
            "Processing file 1NWgd-7IL0Q5VFv0D7d7no1AHj8VhfMuf valid.token.ast\n",
            "Processing file 1EVxJ7Ff2ftcUac-xQAtNsCsu4JLD83QS valid.token.code\n",
            "Processing file 1gAKLFYtEaGBvCDa2EnTJsY9JPmeqclfF valid.token.nl\n",
            "Processing file 1tpSS_2y97B9R-uI1PFHEfT4IrKtmov_9 vocab.code\n",
            "Processing file 1adGWO_Gbq76EXYyHj12jG-PKh7CK7has vocab.nl\n",
            "Retrieving folder 1IMh9wYqvoP675_tynkrcu17QM1SOARmF Python\n",
            "Retrieving folder 1KJqxxWITE1JLpUHz5AcAibHc9dqn1-JT test\n",
            "Processing file 1iAyHjhkzYLprnkEp_IMmgN1ogaReiPP5 split_test_ast.json\n",
            "Processing file 1cqc6CMDMK9c5uGQMPfxYTJ9GzxAFkj16 test.jsonl\n",
            "Processing file 1rVqUNGsEQmXbP4_bQGZM7yzZtS2kB7rK test.token.ast\n",
            "Processing file 1zuyK1CKWpWsQBSMx-DddWQOz6UyMKRvf test.token.code\n",
            "Processing file 1ZTLNi03rK4d3igohMAoyMXSUR2XVienx test.token.nl\n",
            "Processing file 1TLhyDo3tCIGmshfQ7LAd5qSUdMlEet44 test.token.source\n",
            "Retrieving folder 1sZHH5Lf8qHfq-B94OZYCSDwMLnQIkCh2 train\n",
            "Processing file 1q1hr7yTGKzsD9pgyvmegIo4EJAd-Ts74 split_train_ast.json\n",
            "Processing file 1Q-3WkdTWnTSbkNWuFKWS7TGr2UBRo2zy train.jsonl\n",
            "Processing file 14CiYcfzSuVRE-74s38bLKmjPLP3OHGYn train.token.ast\n",
            "Processing file 1q0bw0am3ScbSxWCB54E6p09FKs9hb7SE train.token.code\n",
            "Processing file 1LHlvXSjI2ugg6Fw-ins7K8AHhqd_Rtk9 train.token.nl\n",
            "Processing file 1f716vJuq19XtJHnA2zFMU0IaT21SKmYm train.token.source\n",
            "Retrieving folder 11MfH8gjY-iCTddkI2gAAKvFBP_qAtXDB valid\n",
            "Processing file 1AerAa38hyvwjYOxBCnuS34qLoWU8RB-H split_valid_ast.json\n",
            "Processing file 1pU0wpcwU5aYHT0PElM2h3TUiz2QnI5Rl valid.jsonl\n",
            "Processing file 1epeqJGqhTDYsOFJd8Py_PlnboX955diD valid.token.ast\n",
            "Processing file 1BPjIYAx3yyw83-TUYWrUZEQ4vbk9xe32 valid.token.code\n",
            "Processing file 1OXC4emFLbO65vtKReXWPfWPF4vbxrF6D valid.token.nl\n",
            "Processing file 1hjBWiNgeYZhEfZfVpM6slYyAPDwv3BLX valid.token.source\n",
            "Processing file 162w25nLQW2dGFq93ZdRV6XM25LUb27Fc vocab.code\n",
            "Processing file 1196Hk5i2snraR1dXu5V4NmeB6W7wetSO vocab.nl\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Znbl3fJPaq5ki-oie9FLIyaJdkHaaRcU\n",
            "To: /content/adamo/src/split_test_ast.json\n",
            "100% 19.3M/19.3M [00:00<00:00, 161MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OnZ6Wv4hGmbyqZoy9rfuX5rec3cIDJtN\n",
            "To: /content/adamo/src/test.source\n",
            "100% 3.00M/3.00M [00:00<00:00, 179MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sIZAfZj2ob37hNb3cjP-rRrffAXwH0G5\n",
            "To: /content/adamo/src/test.token.ast\n",
            "100% 171M/171M [00:01<00:00, 149MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AKek2SWz4AXJL7Kh17-Qss4w3fl2SnFT\n",
            "To: /content/adamo/src/test.token.code\n",
            "100% 3.15M/3.15M [00:00<00:00, 229MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 377, in _make_request\n",
            "TypeError: getresponse() got an unexpected keyword argument 'buffering'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gdown\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gdown/cli.py\", line 152, in main\n",
            "    remaining_ok=args.remaining_ok,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gdown/download_folder.py\", line 349, in download_folder\n",
            "    use_cookies=use_cookies,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gdown/download.py\", line 146, in download\n",
            "    res = sess.get(url, headers=headers, stream=True, verify=verify)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 543, in get\n",
            "    return self.request('GET', url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 380, in _make_request\n",
            "    httplib_response = conn.getresponse()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1373, in getresponse\n",
            "    response.begin()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 319, in begin\n",
            "    version, status, reason = self._read_status()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 280, in _read_status\n",
            "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 929, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "## download dataset\n",
        "!pip install gdown\n",
        "!gdown --folder https://drive.google.com/drive/folders/12N-pBzlHhoIgSku7onVPvQrc_JQJw1Q9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download dependencies according to the requirements mentioned in the repository\n",
        "!pip install absl-py==0.13.0\n",
        "!pip install attrs==21.2.0\n",
        "!pip install chardet==4.0.0\n",
        "!pip install datasets==1.11.0\n",
        "!pip install pandas==1.2.5\n",
        "!pip install rouge-score==0.0.4\n",
        "!pip install torch==1.7.1  # 1.8.1\n",
        "!pip install tqdm==4.61.2\n",
        "!pip install transformers==4.8.2  # 4.9.2 4.10.3\n",
        "!pip install git+https://github.com/Maluuba/nlg-eval.git@master\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kTJs9oFzfDVQ",
        "outputId": "f333652a-ada3-42cf-b45d-c56015bd3c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting absl-py==0.13.0\n",
            "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py==0.13.0) (1.15.0)\n",
            "Installing collected packages: absl-py\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires absl-py>=1.0.0, but you have absl-py 0.13.0 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting attrs==21.2.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: attrs\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 22.1.0\n",
            "    Uninstalling attrs-22.1.0:\n",
            "      Successfully uninstalled attrs-22.1.0\n",
            "Successfully installed attrs-21.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 32.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: chardet\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires chardet<4,>=3.0.2, but you have chardet 4.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed chardet-4.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets==1.11.0\n",
            "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 26.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (21.3)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (4.64.1)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (2022.10.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (4.13.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.11.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0) (3.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.11.0) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.11.0) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.11.0) (2022.9.24)\n",
            "Collecting chardet<4,>=3.0.2\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 71.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.11.0) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.11.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.11.0) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.11.0) (1.15.0)\n",
            "Installing collected packages: chardet, xxhash, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "Successfully installed chardet-3.0.4 datasets-1.11.0 huggingface-hub-0.0.19 multiprocess-0.70.14 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.2.5\n",
            "  Downloading pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.5) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.5) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.5) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "Successfully installed pandas-1.2.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge-score==0.0.4\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4) (1.21.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4) (3.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score==0.0.4) (0.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score==0.0.4) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score==0.0.4) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score==0.0.4) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge-score==0.0.4) (4.64.1)\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tqdm==4.61.2\n",
            "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.61.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.8.2\n",
            "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 28.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (4.61.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 29.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (4.13.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.2) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.2) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.2) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=cfd7d226d8124492735435b88ae5071fb9446dc8e89b33a31b519f8538388bf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.0.19\n",
            "    Uninstalling huggingface-hub-0.0.19:\n",
            "      Successfully uninstalled huggingface-hub-0.0.19\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.8.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Maluuba/nlg-eval.git@master\n",
            "  Cloning https://github.com/Maluuba/nlg-eval.git (to revision master) to /tmp/pip-req-build-lvzzhf8i\n",
            "  Running command git clone -q https://github.com/Maluuba/nlg-eval.git /tmp/pip-req-build-lvzzhf8i\n",
            "Requirement already satisfied: nltk>=3.4.5 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (3.7)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (1.21.6)\n",
            "Collecting psutil>=5.6.2\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 29.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (2.23.0)\n",
            "Requirement already satisfied: six>=1.11 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (1.15.0)\n",
            "Requirement already satisfied: Cython>=0.28.5 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (0.29.32)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (1.0.2)\n",
            "Collecting gensim~=3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting Theano>=0.8.1\n",
            "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 26.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.24 in /usr/local/lib/python3.7/dist-packages (from nlg-eval==2.3) (4.61.2)\n",
            "Collecting xdg\n",
            "  Downloading xdg-5.1.1-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=3.8.3->nlg-eval==2.3) (5.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->nlg-eval==2.3) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->nlg-eval==2.3) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.5->nlg-eval==2.3) (2022.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->nlg-eval==2.3) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->nlg-eval==2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->nlg-eval==2.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->nlg-eval==2.3) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17->nlg-eval==2.3) (3.1.0)\n",
            "Building wheels for collected packages: nlg-eval, Theano\n",
            "  Building wheel for nlg-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlg-eval: filename=nlg_eval-2.3-py3-none-any.whl size=68175166 sha256=cb75c5c5da5e1c29482f458994624839db7865e32e068e28c1a3d08d87bfd3b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l30nfckh/wheels/08/20/df/33ced66932f198c4323042d18ff1c2db9b9716369f0de4afb4\n",
            "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano: filename=Theano-1.0.5-py3-none-any.whl size=2668113 sha256=cc5168a78d16b6a2dc871846aba9572e02e6cb63310ebf4d0793d55ad394ba7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/68/6f/745330367ce7822fe0cd863712858151f5723a0a5e322cc144\n",
            "Successfully built nlg-eval Theano\n",
            "Installing collected packages: xdg, Theano, psutil, gensim, nlg-eval\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed Theano-1.0.5 gensim-3.8.3 nlg-eval-2.3 psutil-5.9.4 xdg-5.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_DQqXVDdMzr",
        "outputId": "83b71b24-4f8b-4f35-a7b0-a288fa65ac47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy adamo directory to pwd\n",
        "!cp -r /content/drive/MyDrive/adamo ."
      ],
      "metadata": {
        "id": "2aKV0qGyd7IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/drive/MyDrive/java java"
      ],
      "metadata": {
        "id": "UyJyrIoTuFJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move the dataset to required directory\n",
        "!cp -r /content/ICPC2021_BASTS/Java /content/adamo/data/basts/java"
      ],
      "metadata": {
        "id": "774Xbsm4eHuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd into src dir\n",
        "!ls\n",
        "%cd adamo/src\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4sXex4De3E6",
        "outputId": "42b05150-31db-4269-d2ba-6c28567e6ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metric.py\t__pycache__    t2t_noisy.job  t2t.py\t      t2t_review.sh\n",
            "noisy_model.py\tt2t_adamo.job  t2t_power.job  t2t_review.job  t2t.sh\n",
            "metric.py\t__pycache__    t2t_noisy.job  t2t.py\t      t2t_review.sh\n",
            "noisy_model.py\tt2t_adamo.job  t2t_power.job  t2t_review.job  t2t.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the code\n",
        "!python t2t.py --job basic4basts --lang java --mission train --mark @ --orz adamo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaD69Sevelzu",
        "outputId": "903ad063-3da6-4980-d176-34fb714d459d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(decoder='gpt2', dryrun=False, encoder='codebert', fastrun=False, gaussian=0.0, highrun=False, impulsive=0.0, job='basic4basts', lang='java', mark='@', mission='train', orz='adamo', power=1, wholerun=False)\n",
            "INFO:__main__:Namespace(decoder='gpt2', dryrun=False, encoder='codebert', fastrun=False, gaussian=0.0, highrun=False, impulsive=0.0, job='basic4basts', lang='java', mark='@', mission='train', orz='adamo', power=1, wholerun=False)\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.6.crossattention.q_attn.weight', 'h.6.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.weight', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.3.ln_cross_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.6.crossattention.masked_bias', 'h.1.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.bias', 'h.7.ln_cross_attn.weight', 'h.9.ln_cross_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.5.crossattention.masked_bias', 'h.7.crossattention.masked_bias', 'h.0.crossattention.bias', 'h.2.crossattention.masked_bias', 'h.3.crossattention.bias', 'h.11.crossattention.c_proj.weight', 'h.1.crossattention.bias', 'h.9.crossattention.bias', 'h.5.crossattention.bias', 'h.9.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.1.crossattention.q_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.weight', 'h.0.ln_cross_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.1.crossattention.c_attn.weight', 'h.8.crossattention.masked_bias', 'h.6.crossattention.c_proj.bias', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.masked_bias', 'h.11.crossattention.c_proj.bias', 'h.4.ln_cross_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.10.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.masked_bias', 'h.5.ln_cross_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.5.crossattention.c_attn.weight', 'h.3.crossattention.masked_bias', 'h.1.crossattention.c_proj.bias', 'h.10.crossattention.bias', 'h.7.crossattention.c_proj.weight', 'h.11.ln_cross_attn.weight', 'h.6.crossattention.bias', 'h.6.ln_cross_attn.weight', 'h.2.crossattention.bias', 'h.7.crossattention.q_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.8.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.weight', 'h.7.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.8.ln_cross_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.1.crossattention.masked_bias', 'h.3.crossattention.c_proj.bias', 'h.4.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.bias', 'h.11.crossattention.q_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.bias', 'h.2.ln_cross_attn.weight', 'h.10.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "404 Client Error: Not Found for url: https://huggingface.co//content/adamo/models/pretrained/@adamo_java/resolve/main/config.json\n",
            "Can't load config for '/content/adamo/models/pretrained/@adamo_java'. Make sure that:\n",
            "\n",
            "- '/content/adamo/models/pretrained/@adamo_java' is a correct model identifier listed on 'https://huggingface.co/models'\n",
            "\n",
            "- or '/content/adamo/models/pretrained/@adamo_java' is the correct path to a directory containing a config.json file\n",
            "\n",
            "\n",
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.6.crossattention.q_attn.weight', 'h.6.crossattention.c_attn.weight', 'h.4.crossattention.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.weight', 'h.4.crossattention.masked_bias', 'h.6.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.3.ln_cross_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.6.crossattention.masked_bias', 'h.1.crossattention.c_proj.weight', 'h.10.crossattention.c_proj.bias', 'h.7.ln_cross_attn.weight', 'h.9.ln_cross_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.5.crossattention.masked_bias', 'h.7.crossattention.masked_bias', 'h.0.crossattention.bias', 'h.2.crossattention.masked_bias', 'h.3.crossattention.bias', 'h.11.crossattention.c_proj.weight', 'h.1.crossattention.bias', 'h.9.crossattention.bias', 'h.5.crossattention.bias', 'h.9.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.bias', 'h.11.crossattention.bias', 'h.1.crossattention.q_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.weight', 'h.0.ln_cross_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.1.crossattention.c_attn.weight', 'h.8.crossattention.masked_bias', 'h.6.crossattention.c_proj.bias', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.masked_bias', 'h.11.crossattention.c_proj.bias', 'h.4.ln_cross_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.10.crossattention.masked_bias', 'h.9.crossattention.masked_bias', 'h.8.crossattention.bias', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.masked_bias', 'h.5.ln_cross_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.5.crossattention.c_attn.weight', 'h.3.crossattention.masked_bias', 'h.1.crossattention.c_proj.bias', 'h.10.crossattention.bias', 'h.7.crossattention.c_proj.weight', 'h.11.ln_cross_attn.weight', 'h.6.crossattention.bias', 'h.6.ln_cross_attn.weight', 'h.2.crossattention.bias', 'h.7.crossattention.q_attn.weight', 'h.10.crossattention.c_attn.weight', 'h.8.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.weight', 'h.7.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.8.ln_cross_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.1.crossattention.masked_bias', 'h.3.crossattention.c_proj.bias', 'h.4.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.7.crossattention.bias', 'h.11.crossattention.q_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.bias', 'h.2.ln_cross_attn.weight', 'h.10.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "load the encoder-decoder model\n",
            "INFO:__main__:load the encoder-decoder model\n",
            "tune the encoder-decoder model\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function T2T.tune_model.<locals>._map_to_encoder_decoder_inputs at 0x7fc484a1bd40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100% 1623/1623 [01:40<00:00, 16.13ba/s]\n",
            "100% 51/51 [00:03<00:00, 15.68ba/s]\n",
            "+++++++++ model tuning +++++++++\n",
            "2022-11-16 15:01:31\n",
            "INFO:__main__:+++++++++ model tuning +++++++++\n",
            "INFO:__main__:2022-11-16 15:01:31\n",
            "!!!!!!!!!\n",
            "No valid checkpoint found in output directory (/content/adamo/models/checkpoints/@adamo_java_cf+basts)\n",
            "***** Running training *****\n",
            "  Num examples = 415395\n",
            "  Num Epochs = 8\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3323160\n",
            "{'loss': 6.7658, 'learning_rate': 4.999247703992586e-05, 'epoch': 0.0}\n",
            "  0% 766/3323160 [02:54<215:08:11,  4.29it/s]Traceback (most recent call last):\n",
            "  File \"t2t.py\", line 450, in tune_model\n",
            "    trainer.train(resume_from_checkpoint=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1047, in train\n",
            "    raise ValueError(f\"No valid checkpoint found in output directory ({args.output_dir})\")\n",
            "ValueError: No valid checkpoint found in output directory (/content/adamo/models/checkpoints/@adamo_java_cf+basts)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"t2t.py\", line 829, in <module>\n",
            "    Mission.train_t2t()\n",
            "  File \"t2t.py\", line 604, in train_t2t\n",
            "    T2T.run_pipeline(option, load_path, dump_path)\n",
            "  File \"t2t.py\", line 547, in run_pipeline\n",
            "    T2T.tune_model(option, tokenizer, model)\n",
            "  File \"t2t.py\", line 454, in tune_model\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1269, in train\n",
            "    tr_loss += self.training_step(model, inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1780, in training_step\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 221, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 132, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "  0% 766/3323160 [02:54<210:33:25,  4.38it/s]\n"
          ]
        }
      ]
    }
  ]
}